{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96eb59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_data_200.py\n",
    "import xarray as xr\n",
    "\n",
    "def preprocess_geopotential(filepath):\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    z200 = ds['z'].sel(pressure_level=200).mean(dim='valid_time')\n",
    "    anomalies = ds['z'].sel(pressure_level=200) - z200\n",
    "    anomalies.to_netcdf('z200_anomalies.nc')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_geopotential('india_pressure_level200_2016_2021.nc')  # Replace with your actual file if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c1111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EOF clustering (200 hPa) completed and saved.\n"
     ]
    }
   ],
   "source": [
    "# eof_clustering_200.py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from eofs.xarray import Eof\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def run_eof_clustering():\n",
    "    data = xr.open_dataset('z200_anomalies.nc')['z']\n",
    "    if 'valid_time' in data.dims:\n",
    "        data = data.rename({'valid_time': 'time'})\n",
    "\n",
    "    solver = Eof(data)\n",
    "    pcs = solver.pcs(npcs=7, pcscaling=1)\n",
    "    np.save('pcs_200.npy', pcs.values)\n",
    "\n",
    "    variance = solver.varianceFraction().values[:7]\n",
    "    np.save('explained_variance_200.npy', variance)\n",
    "\n",
    "    pcs_np = pcs.values\n",
    "    pcs_norm = (pcs_np - pcs_np.mean(axis=0)) / pcs_np.std(axis=0)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=4, n_init=10, random_state=42).fit(pcs_norm)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    regimes_ds = xr.Dataset({'regime': (['time'], labels)}, coords={'time': data['time']})\n",
    "    regimes_ds.to_netcdf('eof_weather_regimes_200.nc')\n",
    "\n",
    "    print(\"✅ EOF clustering (200 hPa) completed and saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_eof_clustering()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80139fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_13420\\3824886403.py:18: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=labels, y=counts, palette=\"deep\")\n",
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_13420\\3824886403.py:104: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[f'PC{i+1}' for i in range(7)], y=correlations, palette=\"deep\")\n",
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_13420\\3824886403.py:92: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  pcs_monthly = df.resample('M').mean()\n",
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_13420\\3824886403.py:104: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[f'PC{i+1}' for i in range(7)], y=correlations, palette=\"deep\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def ensure_time(ds):\n",
    "    if 'valid_time' in ds.dims:\n",
    "        ds = ds.rename({'valid_time': 'time'})\n",
    "    return ds\n",
    "\n",
    "def plot_regime_frequency(ds):\n",
    "    labels, counts = np.unique(ds['regime'].values, return_counts=True)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.barplot(x=labels, y=counts, palette=\"deep\")\n",
    "    plt.title(\"Weather Regime Frequency (2016–2021)\", fontsize=14)\n",
    "    plt.xlabel(\"Regime\", fontsize=12)\n",
    "    plt.ylabel(\"Days\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots_200/regime_frequency.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_spatial_composites(ds):\n",
    "    for r in np.unique(ds['regime'].values):\n",
    "        with xr.open_dataset('z200_anomalies.nc') as anomalies:\n",
    "            anomalies = ensure_time(anomalies)\n",
    "            z = anomalies['z']\n",
    "            z_regime = z.where(ds['regime'] == r).mean(dim='time')\n",
    "\n",
    "            plt.figure(figsize=(8,6))\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            z_regime.plot.contourf(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                                   levels=np.arange(-200, 200, 20),\n",
    "                                   cmap='RdBu_r', extend='both', add_colorbar=True)\n",
    "            ax.coastlines()\n",
    "            ax.set_title(f\"Regime {r}: Mean Z200 Anomaly\", fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'plots_200/regime_{r}_z200_composite.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "def plot_pc_timeseries(pcs, nao_index, enso_df):\n",
    "    with xr.open_dataset('z200_anomalies.nc') as anomalies:\n",
    "        anomalies = ensure_time(anomalies)\n",
    "        times = anomalies['time'].values\n",
    "\n",
    "    explained_variance = np.load('explained_variance_200.npy')\n",
    "    pc1_var = explained_variance[0] * 100\n",
    "\n",
    "    enso_df['date'] = pd.to_datetime(enso_df[['Year', 'Month']].assign(day=15))\n",
    "    enso_df = enso_df.set_index('date').loc[\"2016\":\"2021\"]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(times, pcs[:, 0], label='PC1 (EOF1)', linewidth=1.5)\n",
    "    plt.plot(nao_index['time'].values, nao_index['nao'].values, label='NAO Index', linewidth=1.5)\n",
    "    plt.plot(enso_df.index, enso_df['Anomaly'], label='ENSO Index', linewidth=1.5)\n",
    "    plt.legend()\n",
    "    plt.title(f\"PC1 vs NAO and ENSO Index (2016–2021)\\nPC1 Explained Variance = {pc1_var:.2f}%\", fontsize=14)\n",
    "    plt.xlabel(\"Time\", fontsize=12)\n",
    "    plt.ylabel(\"Index Value\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots_200/pc1_vs_enso_nao.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_seasonal_cycle(ds):\n",
    "    ds = ensure_time(ds)\n",
    "    times = ds['time'].to_index()\n",
    "    months = times.month\n",
    "    regimes = ds['regime'].values\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for r in np.unique(regimes):\n",
    "        monthly_counts = [np.sum((months==m) & (regimes==r)) for m in range(1,13)]\n",
    "        plt.plot(range(1,13), monthly_counts, label=f'Regime {r}')\n",
    "    plt.xticks(range(1,13), ['Jan','Feb','Mar','Apr','May','Jun',\n",
    "                             'Jul','Aug','Sep','Oct','Nov','Dec'])\n",
    "    plt.legend()\n",
    "    plt.title(\"Seasonal Cycle of Regime Occurrence\", fontsize=14)\n",
    "    plt.xlabel(\"Month\", fontsize=12)\n",
    "    plt.ylabel(\"Days\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots_200/seasonal_cycle.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_pc_index_correlation(pcs, index_array, label, file_name, time_values=None, index_time=None):\n",
    "    if time_values is not None and index_array.shape[0] != pcs.shape[0]:\n",
    "        # Convert pcs to DataFrame with datetime index\n",
    "        df = pd.DataFrame(pcs, columns=[f\"PC{i+1}\" for i in range(pcs.shape[1])])\n",
    "        df['date'] = pd.to_datetime(time_values)\n",
    "        df = df.set_index('date')\n",
    "        pcs_monthly = df.resample('M').mean()\n",
    "\n",
    "        # Create aligned DataFrame\n",
    "        index_df = pd.Series(index_array, index=index_time)\n",
    "        index_df = index_df.loc[pcs_monthly.index]\n",
    "\n",
    "        # Now calculate correlations\n",
    "        correlations = [np.corrcoef(pcs_monthly.iloc[:, i], index_df)[0, 1] for i in range(pcs.shape[1])]\n",
    "    else:\n",
    "        correlations = [np.corrcoef(pcs[:, i], index_array)[0, 1] for i in range(pcs.shape[1])]\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(x=[f'PC{i+1}' for i in range(7)], y=correlations, palette=\"deep\")\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.title(f\"Correlation between EOF PCs and {label} (2016–2021)\", fontsize=14)\n",
    "    plt.ylabel(\"Pearson Correlation\", fontsize=12)\n",
    "    plt.xlabel(\"Principal Components\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots_200/{file_name}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_spatial_composites_new(ds):\n",
    "    pcs = np.load('pcs_200.npy')\n",
    "    explained_variance = np.load('explained_variance_200.npy')\n",
    "    labels = ds['regime'].values\n",
    "    explained_variance = explained_variance / explained_variance.sum()\n",
    "\n",
    "    regime_variance_map = {}\n",
    "    for r in np.unique(labels):\n",
    "        regime_pcs = pcs[labels == r]\n",
    "        pc_var = np.var(regime_pcs, axis=0)\n",
    "        pc_var_normalized = pc_var / pc_var.sum()\n",
    "        regime_variance = np.sum(pc_var_normalized * explained_variance)\n",
    "        regime_variance_map[r] = regime_variance\n",
    "\n",
    "    for r in np.unique(ds['regime'].values):\n",
    "        with xr.open_dataset('z200_anomalies.nc') as anomalies:\n",
    "            anomalies = ensure_time(anomalies)\n",
    "            z = anomalies['z']\n",
    "            z_regime = z.where(ds['regime'] == r).mean(dim='time')\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            z_regime.plot.contourf(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                                   levels=np.arange(-200, 200, 20),\n",
    "                                   cmap='RdBu_r', extend='both', add_colorbar=True)\n",
    "            ax.coastlines()\n",
    "            variance_str = f\"{regime_variance_map[r]*100:.2f}%\"\n",
    "            ax.set_title(f\"Regime {r}: Mean Z200 Anomaly\\n(Weighted EOF Variance ≈ {variance_str})\", fontsize=13)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'plots_200_rand/regime_{r}_z200_composite.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "def main():\n",
    "    os.makedirs(\"plots_200\", exist_ok=True)\n",
    "    os.makedirs(\"plots_200_rand\", exist_ok=True)\n",
    "\n",
    "    with xr.open_dataset('eof_weather_regimes_200.nc') as ds:\n",
    "        ds = ensure_time(ds)\n",
    "        pcs = np.load('pcs_200.npy')\n",
    "\n",
    "        # Load NAO index\n",
    "        with xr.open_dataset('nao_index.nc') as nao_index:\n",
    "            # Load ENSO index CSV\n",
    "            enso_df = pd.read_csv('Enso_Monthwise_Index.csv')\n",
    "            enso_df['date'] = pd.to_datetime(enso_df[['Year', 'Month']].assign(day=15))\n",
    "            # Convert to month-end to match resampled PC dates\n",
    "            enso_df['date'] = pd.to_datetime(enso_df[['Year', 'Month']].assign(day=1)) + pd.offsets.MonthEnd(0)\n",
    "            enso_df = enso_df.set_index('date').loc[\"2016-01-31\":\"2021-12-31\"]\n",
    "            enso_series = enso_df['Anomaly'].values\n",
    "\n",
    "            # Interpolate NAO to match pcs time\n",
    "            anomalies = xr.open_dataset('z200_anomalies.nc')\n",
    "            anomalies = ensure_time(anomalies)\n",
    "            time_values = anomalies['time'].values\n",
    "            f_nao = interp1d(nao_index['time'].values.astype(np.int64),\n",
    "                             nao_index['nao'].values, kind='linear', fill_value=\"extrapolate\")\n",
    "            nao_interp = f_nao(time_values.astype(np.int64))\n",
    "\n",
    "            plot_regime_frequency(ds)\n",
    "            plot_spatial_composites(ds)\n",
    "            plot_pc_timeseries(pcs, nao_index, enso_df)\n",
    "            plot_pc_index_correlation(pcs, nao_interp, \"NAO Index\", \"pc_nao_correlation\")\n",
    "            plot_pc_index_correlation(\n",
    "                pcs,\n",
    "                enso_series,\n",
    "                \"ENSO Index\",\n",
    "                \"pc_enso_correlation\",\n",
    "                time_values=time_values,\n",
    "                index_time=enso_df.index\n",
    "            )\n",
    "\n",
    "            plot_seasonal_cycle(ds)\n",
    "            plot_spatial_composites_new(ds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa1062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extreme_risk_ratio(power_data, regimes):\n",
    "    thresholds = np.percentile(power_data, 5)  # define extreme event threshold\n",
    "    rr = []\n",
    "    for r in np.unique(regimes):\n",
    "        regime_days = power_data[regimes == r]\n",
    "        p_wr = np.sum(regime_days < thresholds) / len(regime_days)\n",
    "        p_clim = np.sum(power_data < thresholds) / len(power_data)\n",
    "        ratio = p_wr / p_clim if p_clim > 0 else np.nan\n",
    "        rr.append(ratio)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x=np.unique(regimes), y=rr)\n",
    "    plt.title(\"Extreme Energy Shortfall Risk Ratio by Regime\")\n",
    "    plt.xlabel(\"Regime\")\n",
    "    plt.ylabel(\"Risk Ratio\")\n",
    "    plt.savefig(\"plots/extreme_risk_ratio.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_pc_scatter_trajectories(pcs, regimes):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    scatter = plt.scatter(pcs[:,0], pcs[:,1], c=regimes, cmap='tab10', s=10)\n",
    "    plt.colorbar(scatter, label='Regime')\n",
    "    plt.title(\"Regime Transitions in PC1-PC2 Phase Space\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.savefig(\"plots/pc_phase_space.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_teleconnection_correlation(pcs, teleconnection_indices):\n",
    "    pc_array = pcs.values\n",
    "    indices_array = teleconnection_indices.values\n",
    "    combined = np.hstack([pc_array, indices_array])\n",
    "    corr_matrix = np.corrcoef(combined.T)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", \n",
    "                xticklabels=['PC1','PC2','PC3','NAO','IOD','MJO'],\n",
    "                yticklabels=['PC1','PC2','PC3','NAO','IOD','MJO'])\n",
    "    plt.title(\"Correlation Matrix: PCs vs Teleconnections\")\n",
    "    plt.savefig(\"plots/teleconnection_correlation.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_composite_anomalies(ds, variable_name, levels=None, cmap=\"RdBu_r\"):\n",
    "    if levels is None:\n",
    "        levels = np.linspace(-2, 2, 21)\n",
    "    for r in np.unique(ds['regime'].values):\n",
    "        subset = ds[variable_name].where(ds['regime'] == r).mean(dim='time')\n",
    "        plt.figure(figsize=(8,6))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        subset.plot.contourf(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                             levels=levels, cmap=cmap, extend='both')\n",
    "        ax.coastlines()\n",
    "        ax.set_title(f\"Regime {r}: {variable_name} Anomaly Composite\")\n",
    "        plt.savefig(f\"plots/{variable_name}_regime_{r}_composite.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# plot_composite_anomalies(ds, 'u_component_of_wind')\n",
    "# plot_composite_anomalies(ds, 'v_component_of_wind')\n",
    "# plot_composite_anomalies(ds, 'temperature')\n",
    "# plot_composite_anomalies(ds, 'relative_humidity')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df428ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary_panel(ds):\n",
    "    fig, axes = plt.subplots(2,2, figsize=(12,10))\n",
    "    \n",
    "    # A: Regime frequency\n",
    "    labels, counts = np.unique(ds['regime'].values, return_counts=True)\n",
    "    axes[0,0].bar(labels, counts)\n",
    "    axes[0,0].set_title(\"Regime Frequency\")\n",
    "    \n",
    "    # B: Seasonal cycle\n",
    "    times = ds['time'].to_index()\n",
    "    months = [t.month for t in times]\n",
    "    regimes = ds['regime'].values\n",
    "    for r in np.unique(regimes):\n",
    "        monthly_counts = [np.sum((np.array(months)==m) & (regimes==r)) for m in range(1,13)]\n",
    "        axes[0,1].plot(range(1,13), monthly_counts, label=f'Regime {r}')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].set_title(\"Seasonal Cycle\")\n",
    "    axes[0,1].set_xticks(range(1,13))\n",
    "    axes[0,1].set_xticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
    "    \n",
    "    # C: Phase space\n",
    "    pcs = ds['pcs'].values if 'pcs' in ds else np.random.randn(len(ds['time']), 2)  # dummy example\n",
    "    scatter = axes[1,0].scatter(pcs[:,0], pcs[:,1], c=ds['regime'].values, cmap='tab10', s=10)\n",
    "    fig.colorbar(scatter, ax=axes[1,0])\n",
    "    axes[1,0].set_title(\"PC1-PC2 Phase Space\")\n",
    "    \n",
    "    # D: Co-occurrence matrix\n",
    "    # wind_regimes & solar_regimes must be defined\n",
    "    # Dummy example\n",
    "    matrix = np.random.randint(0,100,(4,4))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\"0.0f\", cmap=\"viridis\", ax=axes[1,1])\n",
    "    axes[1,1].set_title(\"Wind vs Solar Co-occurrence\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/summary_panel.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcef419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ds = xr.open_dataset('eof_weather_regimes.nc')\n",
    "    pcs = xr.open_dataset('z500_anomalies.nc')['z']  # or your PCs dataset\n",
    "    tele = xr.open_dataset('teleconnections.nc')  # must be prepared\n",
    "    \n",
    "    power_data = np.load('daily_renewable_power.npy')  # must be prepared\n",
    "    regimes = ds['regime'].values\n",
    "    wind_regimes = regimes  # example\n",
    "    solar_regimes = regimes  # example\n",
    "\n",
    "    plot_extreme_risk_ratio(power_data, regimes)\n",
    "    plot_pc_scatter_trajectories(pcs, regimes)\n",
    "    plot_teleconnection_correlation(pcs, tele)\n",
    "    plot_composite_anomalies(ds, 'u_component_of_wind')\n",
    "    plot_composite_anomalies(ds, 'v_component_of_wind')\n",
    "    plot_composite_anomalies(ds, 'temperature')\n",
    "    plot_composite_anomalies(ds, 'relative_humidity')\n",
    "    plot_summary_panel(ds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
