{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b830613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Daily anomalies saved to 'tnlwrfcs_anomalies_2001_2015.nc'\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "def preprocess_tnlwrfcs(filepath):\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    var = ds['avg_tnlwrfcs']\n",
    "    \n",
    "    # Ensure time is renamed for consistency\n",
    "    if 'valid_time' in var.dims:\n",
    "        var = var.rename({'valid_time': 'time'})\n",
    "    \n",
    "    # Daily mean (assuming 6-hourly data, so 4 steps/day)\n",
    "    var_daily = var.resample(time='1D').mean()\n",
    "\n",
    "    # Climatology (mean across all days)\n",
    "    climatology = var_daily.mean(dim='time')\n",
    "\n",
    "    # Daily anomalies\n",
    "    anomalies = var_daily - climatology\n",
    "    anomalies.name = 'avg_tnlwrfcs'\n",
    "\n",
    "    anomalies.to_netcdf('tnlwrfcs_anomalies_2001_2015.nc')\n",
    "    print(\"✅ Daily anomalies saved to 'tnlwrfcs_anomalies_2001_2015.nc'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_tnlwrfcs('OLR_data.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42eb1f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 340MB\n",
      "Dimensions:       (latitude: 129, longitude: 121, time: 5449)\n",
      "Coordinates:\n",
      "  * latitude      (latitude) float64 1kB 38.0 37.75 37.5 37.25 ... 6.5 6.25 6.0\n",
      "  * longitude     (longitude) float64 968B 68.0 68.25 68.5 ... 97.5 97.75 98.0\n",
      "  * time          (time) datetime64[ns] 44kB 2001-01-01 ... 2015-12-02\n",
      "    number        int64 8B ...\n",
      "Data variables:\n",
      "    avg_tnlwrfcs  (time, latitude, longitude) float32 340MB ...\n",
      "<xarray.DataArray 'avg_tnlwrfcs' (latitude: 129, longitude: 121)> Size: 62kB\n",
      "[15609 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float64 1kB 38.0 37.75 37.5 37.25 ... 6.5 6.25 6.0\n",
      "  * longitude  (longitude) float64 968B 68.0 68.25 68.5 ... 97.5 97.75 98.0\n",
      "    time       datetime64[ns] 8B 2001-01-01\n",
      "    number     int64 8B ...\n",
      "-5.4464104323415086e-05\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "ds = xr.open_dataset('tnlwrfcs_anomalies_2001_2015.nc')\n",
    "print(ds)\n",
    "print(ds['avg_tnlwrfcs'].isel(time=0))  # Check a sample day\n",
    "print(ds['avg_tnlwrfcs'].mean().item())  # Should not be nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199674cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned data shape: (360, 129, 121)\n",
      "Remaining NaNs: 0\n",
      "✅ EOF clustering for tnlwrfcs completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from eofs.xarray import Eof\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def run_eof_clustering():\n",
    "    data = xr.open_dataset('tnlwrfcs_anomalies_2001_2015.nc')['avg_tnlwrfcs']\n",
    "\n",
    "    if 'valid_time' in data.dims:\n",
    "        data = data.rename({'valid_time': 'time'})\n",
    "\n",
    "    # Drop time steps that are fully NaN\n",
    "    data = data.dropna(dim='time', how='all')\n",
    "\n",
    "    # Optional: Print remaining data size\n",
    "    print(\"✅ Cleaned data shape:\", data.shape)\n",
    "    print(\"Remaining NaNs:\", np.isnan(data.values).sum())\n",
    "\n",
    "    solver = Eof(data)\n",
    "    pcs = solver.pcs(npcs=7, pcscaling=1)\n",
    "\n",
    "    np.save('pcs_tnlwrfcs.npy', pcs.values)\n",
    "    variance = solver.varianceFraction().values[:7]\n",
    "    np.save('explained_variance_tnlwrfcs.npy', variance)\n",
    "\n",
    "    pcs_np = pcs.values\n",
    "    pcs_norm = (pcs_np - pcs_np.mean(axis=0)) / pcs_np.std(axis=0)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=4, n_init=10, random_state=42).fit(pcs_norm)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    regimes_ds = xr.Dataset({'regime': (['time'], labels)}, coords={'time': data['time']})\n",
    "    regimes_ds.to_netcdf('eof_weather_regimes_tnlwrfcs.nc')\n",
    "\n",
    "    print(\"✅ EOF clustering for tnlwrfcs completed and saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_eof_clustering()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd4292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_34348\\3060929473.py:18: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=labels, y=counts, palette=\"deep\")\n",
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_34348\\3060929473.py:102: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[f'PC{i+1}' for i in range(7)], y=correlations, palette=\"deep\")\n",
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_34348\\3060929473.py:92: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  pcs_monthly = df.resample('M').mean()\n",
      "C:\\Users\\medhr\\AppData\\Local\\Temp\\ipykernel_34348\\3060929473.py:102: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[f'PC{i+1}' for i in range(7)], y=correlations, palette=\"deep\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def ensure_time(ds):\n",
    "    if 'valid_time' in ds.dims:\n",
    "        ds = ds.rename({'valid_time': 'time'})\n",
    "    return ds\n",
    "\n",
    "def plot_regime_frequency(ds):\n",
    "    labels, counts = np.unique(ds['regime'].values, return_counts=True)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.barplot(x=labels, y=counts, palette=\"deep\")\n",
    "    plt.title(\"TNLWRFCS Regime Frequency (2001–2015)\", fontsize=14)\n",
    "    plt.xlabel(\"Regime\", fontsize=12)\n",
    "    plt.ylabel(\"Days\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots_tnlwrfcs/regime_frequency.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_spatial_composites(ds):\n",
    "    for r in np.unique(ds['regime'].values):\n",
    "        with xr.open_dataset('tnlwrfcs_anomalies_2001_2015.nc') as anomalies:\n",
    "            anomalies = ensure_time(anomalies)\n",
    "            z = anomalies['avg_tnlwrfcs'].dropna(dim='time', how='all')\n",
    "            z_regime = z.where(ds['regime'] == r).mean(dim='time')\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            z_regime.plot.contourf(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                                   levels=np.arange(-20, 20.1, 2),\n",
    "                                   cmap='RdBu_r', extend='both', add_colorbar=True)\n",
    "            ax.coastlines()\n",
    "            ax.set_title(f\"Regime {r}: Mean TNLWRFCS Anomaly\", fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'plots_tnlwrfcs/regime_{r}_composite.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "def plot_pc_timeseries(pcs, nao_index, enso_df):\n",
    "    with xr.open_dataset('tnlwrfcs_anomalies_2001_2015.nc') as anomalies:\n",
    "        anomalies = ensure_time(anomalies).dropna(dim='time', how='all')\n",
    "        times = anomalies['time'].values\n",
    "\n",
    "    explained_variance = np.load('explained_variance_tnlwrfcs.npy')\n",
    "    pc1_var = explained_variance[0] * 100\n",
    "\n",
    "    enso_df['date'] = pd.to_datetime(enso_df[['Year', 'Month']].assign(day=15))\n",
    "    enso_df = enso_df.set_index('date')\n",
    "    enso_df_filtered = enso_df.loc[\"2001-01-01\":\"2015-12-31\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(times, pcs[:, 0], label='PC1 (EOF1)', linewidth=1.5)\n",
    "    plt.plot(nao_index['time'].values, nao_index['nao'].values, label='NAO Index', linewidth=1.5)\n",
    "    plt.plot(enso_df_filtered.index, enso_df_filtered['Anomaly'], label='ENSO Index (2001–2015)', linewidth=1.5)\n",
    "    plt.legend()\n",
    "    plt.title(f\"PC1 vs NAO and ENSO Index (2001–2015)\\nPC1 Explained Variance = {pc1_var:.2f}%\", fontsize=14)\n",
    "    plt.xlabel(\"Time\", fontsize=12)\n",
    "    plt.ylabel(\"Index Value\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots_tnlwrfcs/pc1_vs_enso_nao.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_seasonal_cycle(ds):\n",
    "    ds = ensure_time(ds)\n",
    "    times = ds['time'].to_index()\n",
    "    months = times.month\n",
    "    regimes = ds['regime'].values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for r in np.unique(regimes):\n",
    "        monthly_counts = [np.sum((months == m) & (regimes == r)) for m in range(1, 13)]\n",
    "        plt.plot(range(1, 13), monthly_counts, label=f'Regime {r}')\n",
    "    plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    plt.legend()\n",
    "    plt.title(\"Seasonal Cycle of Regime Occurrence\", fontsize=14)\n",
    "    plt.xlabel(\"Month\", fontsize=12)\n",
    "    plt.ylabel(\"Days\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots_tnlwrfcs/seasonal_cycle.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_pc_index_correlation(pcs, index_array, label, file_name, time_values=None, index_time=None):\n",
    "    if time_values is not None and index_array.shape[0] != pcs.shape[0]:\n",
    "        df = pd.DataFrame(pcs, columns=[f\"PC{i+1}\" for i in range(pcs.shape[1])])\n",
    "        df['date'] = pd.to_datetime(time_values)\n",
    "        df = df.set_index('date')\n",
    "        pcs_monthly = df.resample('M').mean()\n",
    "\n",
    "        index_df = pd.Series(index_array, index=index_time)\n",
    "        index_df = index_df.loc[pcs_monthly.index]\n",
    "\n",
    "        correlations = [np.corrcoef(pcs_monthly.iloc[:, i], index_df)[0, 1] for i in range(pcs.shape[1])]\n",
    "    else:\n",
    "        correlations = [np.corrcoef(pcs[:, i], index_array)[0, 1] for i in range(pcs.shape[1])]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x=[f'PC{i+1}' for i in range(7)], y=correlations, palette=\"deep\")\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.title(f\"Correlation between EOF PCs and {label} (2001–2015)\", fontsize=14)\n",
    "    plt.ylabel(\"Pearson Correlation\", fontsize=12)\n",
    "    plt.xlabel(\"Principal Components\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots_tnlwrfcs/{file_name}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_spatial_composites_new(ds):\n",
    "    pcs = np.load('pcs_tnlwrfcs.npy')\n",
    "    explained_variance = np.load('explained_variance_tnlwrfcs.npy')\n",
    "    labels = ds['regime'].values\n",
    "    explained_variance = explained_variance / explained_variance.sum()\n",
    "\n",
    "    regime_variance_map = {}\n",
    "    for r in np.unique(labels):\n",
    "        regime_pcs = pcs[labels == r]\n",
    "        pc_var = np.var(regime_pcs, axis=0)\n",
    "        pc_var_normalized = pc_var / pc_var.sum()\n",
    "        regime_variance = np.sum(pc_var_normalized * explained_variance)\n",
    "        regime_variance_map[r] = regime_variance\n",
    "\n",
    "    for r in np.unique(ds['regime'].values):\n",
    "        with xr.open_dataset('tnlwrfcs_anomalies_2001_2015.nc') as anomalies:\n",
    "            anomalies = ensure_time(anomalies).dropna(dim='time', how='all')\n",
    "            z = anomalies['avg_tnlwrfcs']\n",
    "            z_regime = z.where(ds['regime'] == r).mean(dim='time')\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            z_regime.plot.contourf(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                                   levels=np.arange(-20, 20.1, 2),\n",
    "                                   cmap='RdBu_r', extend='both', add_colorbar=True)\n",
    "            ax.coastlines()\n",
    "            variance_str = f\"{regime_variance_map[r] * 100:.2f}%\"\n",
    "            ax.set_title(f\"Regime {r}: Mean TNLWRFCS Anomaly\\n(Weighted EOF Variance ≈ {variance_str})\", fontsize=13)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'plots_tnlwrfcs_rand/regime_{r}_composite.png', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "def main():\n",
    "    os.makedirs(\"plots_tnlwrfcs\", exist_ok=True)\n",
    "    os.makedirs(\"plots_tnlwrfcs_rand\", exist_ok=True)\n",
    "\n",
    "    with xr.open_dataset('eof_weather_regimes_tnlwrfcs.nc') as ds:\n",
    "        ds = ensure_time(ds)\n",
    "        pcs = np.load('pcs_tnlwrfcs.npy')\n",
    "\n",
    "        with xr.open_dataset('nao_index.nc') as nao_index:\n",
    "            enso_df = pd.read_csv('Enso_Monthwise_Index.csv')\n",
    "            enso_df['date'] = pd.to_datetime(enso_df[['Year', 'Month']].assign(day=1)) + pd.offsets.MonthEnd(0)\n",
    "            enso_df = enso_df.set_index('date').loc[\"2001-01-31\":\"2015-12-31\"]\n",
    "            enso_series = enso_df['Anomaly'].values\n",
    "\n",
    "            anomalies = xr.open_dataset('tnlwrfcs_anomalies_2001_2015.nc')\n",
    "            anomalies = ensure_time(anomalies).dropna(dim='time', how='all')\n",
    "            time_values = anomalies['time'].values\n",
    "\n",
    "            f_nao = interp1d(nao_index['time'].values.astype(np.int64),\n",
    "                             nao_index['nao'].values, kind='linear', fill_value=\"extrapolate\")\n",
    "            nao_interp = f_nao(time_values.astype(np.int64))\n",
    "\n",
    "            plot_regime_frequency(ds)\n",
    "            plot_spatial_composites(ds)\n",
    "            plot_pc_timeseries(pcs, nao_index, enso_df)\n",
    "            plot_pc_index_correlation(pcs, nao_interp, \"NAO Index\", \"pc_nao_correlation\")\n",
    "            plot_pc_index_correlation(pcs, enso_series, \"ENSO Index\", \"pc_enso_correlation\",\n",
    "                                      time_values=time_values, index_time=enso_df.index)\n",
    "            plot_seasonal_cycle(ds)\n",
    "            plot_spatial_composites_new(ds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743c5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
